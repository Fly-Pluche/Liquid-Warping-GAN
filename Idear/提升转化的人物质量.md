

# 思想

提高背景图像的复杂度：在得到仿射点的地方做文章（用u2net扣）

### 灵感

我发现，训练集与测试集中背景图偏于单一，为了提高该网络的鲁棒性，让它能模仿具有复杂背景的动图。

由于有一个U2net的模型，所以我打算使用它进行改进。

### 思路

通过U2net直接得到$I_{bg}与I_{ft}$然后再输入生成器中

![image-20210721151802117](C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210721151802117.png)

### 缺点

- 由于训练集与测试集的原因，$G_{BG}$可能对较为复杂的$I_{bg}$无法生成较为真实的$\hat{I}_{bg}$

(解决思路：冻结除$G_{BG}$的网络结构，然后自己做训练集扔进去训练？？)

# 探索过程

## 重构过程

![image-20210721155909964](C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210721155909964.png)

![image-20210721153558000](C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210721153558000.png)

![image-20210721153641582](C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210721153641582.png)![image-20210721153839930](C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210721153839930.png)

以上input_G_src_bg=self._input_G_bg=bg_inputs=concat(前景图,背景图)

然后将其送入self.bg_model中，重构。

## 需要添加的地方

![image-20210721155909964](C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210721155909964.png)

修改input_G_src_bg即可。

### 修改代码

| 原图       | ![0001](D:\GitHub_repositories\Face-recognition\0001.jpg)    |                                                              |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| hmr        | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210731163543716.png" alt="image-20210731163543716" style="zoom:50%;" /> | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210731163623328.png" alt="image-20210731163623328" style="zoom:50%;" /> |
| U^2^GE-net | ![22](D:\GitHub_repositories\Face-recognition\22.png)        | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801122919588.png" alt="image-20210801122919588" style="zoom: 33%;" /> |
|            |                                                              |                                                              |

`发现：`

原本得到的mask是通过SMPL（人体多模态）得到的，因此得到的mask更符合人体的特征曲线

但是这个精细的mask是由一个粗略的人体mask掩码通过SMPL辅助后处理得到的：

<img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801154050353.png" alt="image-20210801154050353" style="zoom:25%;" /><img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210731163543716.png" alt="image-20210731163543716" style="zoom: 25%;" />

为啥上面这个图通过HMR处理的mask就这么好，而其他的就很垃圾？

因为训练就是拿这几张图去练的，网络的泛化性不太好，所以就表现的比较差。





# text.py

*V1：*<kbd>D:\workspace\impersonator-master\models\imitator.py</kbd>

```python
ft_mask_img=U2GE_net.net(src_path)
ft_mask_img=ft_mask_img.unsqueeze(1)
ft_mask_img = ft_mask_img.cuda()
src_inputs = torch.cat([img * ft_mask_img, src_info['cond']], dim=1)
```

## 简单背景图片

我们先试试他们提供的图片（背景简单）

<p> 
<p>Origin:<p>
    <video src="..\History\U2GE_net\simple_bg\009_5_1_000_original\acrobat\mixamo_0007_009_5_1_000.mp4" ></video>
<p>U2GE-net:</p>
    <video src="..\History\U2GE_net\simple_bg\009_5_1_000\acrobat\mixamo_0007_009_5_1_000.mp4"></video>
</p>


| origin     | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801125944164.png" alt="image-20210801125944164" style="zoom: 25%;" /> | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801130348952.png" alt="image-20210801130348952" style="zoom:50%;" /> |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| U^2^GE-net | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801125932611.png" alt="image-20210801125932611" style="zoom: 25%;" /> | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801130407176.png" alt="image-20210801130407176" style="zoom:50%;" /> |
| 对比       | U2GE-net明显在下半身没有更好的表现                           | 使用U^2^GE-net得到的视频可能会因为抠图的不稳定，导致转化的图片产生白块。 |

## *总结*

- U2GE-net 得出的视频，下半身明显更加粗糙，缺少原来的线条
- U2GE-net得到的视频整体质量受到抠图的影响，可能会产生``更多``白块，以及其他的干扰斑点
- 在大幅度的动作上，U2GE-net的效果略有提升。原来的视频在大动作上显得凌乱，而添加U2GE-net后的视频显的更加井井有条。

> U2GE-net在简单背景图上虽然有一点提升，但是弊大于利，故U2GE-net不适合添加



原因：人在图片中的占比较大，导致背景恢复网络得到的信息太少。

并且两者的效果都变差了

视频出现了更多凌乱的干扰块。

*V1*：**default**





*V2：*<kbd>D:\workspace\impersonator-master\models\imitator.py</kbd>

也就是基于上面的`发现`把抠图后的mask也扔进util.morph结合SMPL的信息进行处理

```python
ft_mask_img=U2GE_net.net(src_path)
ft_mask_img = ft_mask_img.cuda()
ft_mask_img = 1 - util.morph(ft_mask_img, ks=self._opt.ft_ks, mode='erode')
src_inputs = torch.cat([img * ft_mask_img, src_info['cond']], dim=1)
```

这是什么牛马啊！！！

人体旁边还有黑影，不科学。。。

![image-20210801164537312](C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801164537312.png)

哦，搞错了。。。

*V2.1：*<kbd>D:\workspace\impersonator-master\models\imitator.py</kbd>

```python
ft_mask_img=U2GE_net.net(src_path)
ft_mask_img[ft_mask_img<0.1]=0
ft_mask_img[ft_mask_img>=0.1]=1
ft_mask_img=ft_mask_img.unsqueeze(0)
ft_mask_img = ft_mask_img.cuda()
ft_mask_img = util.morph(ft_mask_img, ks=self._opt.ft_ks, mode='erode')
src_inputs = torch.cat([img * ft_mask_img, src_info['cond']], dim=1)
```



| img             | ![image-20210801191826934](C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801191826934.png) | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801200003171.png" alt="image-20210801200003171" style="zoom:50%;" /> |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| origin          | ![image-20210801191736021](C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801191736021.png) | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801195848186.png" alt="image-20210801195848186" style="zoom: 50%;" /> |
| U2GE-net        | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801173956377.png" alt="image-20210801173956377" style="zoom:50%;" /> | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801195921814.png" alt="image-20210801195921814" style="zoom: 50%;" /> |
| U2GE-net+origin | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801174006748.png" alt="image-20210801174006748" style="zoom:50%;" /> | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801195941243.png" alt="image-20210801195941243" style="zoom:50%;" /> |
|                 |                                                              |                                                              |

### 结果

<img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210803153613172.png" alt="image-20210803153613172" style="zoom:25%;" /><img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210803153627426.png" alt="image-20210803153627426" style="zoom: 25%;" />

| Original | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210803155023916.png" alt="image-20210803155023916" style="zoom: 50%;" /> | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210803154848632.png" alt="image-20210803154848632" style="zoom: 25%;" /> | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210803154920821.png" alt="image-20210803154920821" style="zoom:25%;" /> |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| U2GE-net | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210803155336134.png" alt="image-20210803155336134" style="zoom: 25%;" /> | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210803155355305.png" alt="image-20210803155355305" style="zoom: 50%;" /> | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210803155407175.png" alt="image-20210803155407175" style="zoom: 50%;" /> |
|          |                                                              |                                                              |                                                              |
|          |                                                              |                                                              |                                                              |

### 评估

感觉结果相差不大，目前没有发现特别的提升。。。

### 猜想

<img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210801205710893.png" alt="image-20210801205710893" style="zoom: 33%;" />

虽然我改进了$I_{bg}$​，但是相关的SMPL参数（eg:$C_s,T,C_t$​）并没有因此发生变化，导致I$_{syn}$变得奇怪，没有预想中的好。

*V3:*

# 3.2  抠图后进行3D姿态提取

<kbd>D:\workspace\impersonator-master\models\imitator.py</kbd> 94行

```python
if src_smpl is None:
    img_hmr = cv_utils.transform_img(ori_img, 224, transpose=True) * 2 - 1.0
    img_hmr = torch.tensor(img_hmr, dtype=torch.float32).cuda()[None, ...]
    src_smpl = self.hmr(img_hmr)   # src_smpl = [1,85]
```



<kbd>D:\workspace\impersonator-master\models\imitator.py</kbd> 415行

```python
def img_center(self,tgt_path):
    mask=U2GE_net.net(tgt_path,1)
    mask = mask.astype(np.uint8)
    # mask=0~255
    mask = mask[:, :, 0]*255
    # mask两个维度
    cnts = (cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE))[1]
    # print(cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE))

    c = sorted(cnts, key=cv2.contourArea, reverse=True)[0]  # contourArea这计算图像轮廓的面积  从大到小排,取最大

    rect = cv2.boundingRect(c)  # minAreaRect就是求出在上述点集下的最小面积矩形

    x = rect[0] - 10
    y = rect[1] - 10
    wight = rect[2]
    height = rect[3]
    if height >= wight:
        x = x - (height - wight) / 2
        wight = height

    else:
        y = y - (wight - height) / 2
        height = wight

    if y < 0:
        y = 0
    if x < 0:
        x = 0

    img = cv2.imread(tgt_path)
    img = img[int(y):int(y + height), int(x):int(x + wight), :]
    ori_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return ori_img
```

|        | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210813173820453.png" alt="image-20210813173820453" style="zoom: 25%;" /> |
| ------ | ------------------------------------------------------------ |
| before | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210813173757270.png" alt="image-20210813173757270" style="zoom: 50%;" /> |
| now    | <img src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210813173745908.png" alt="image-20210813173745908" style="zoom: 50%;" /> |
|        |                                                              |
